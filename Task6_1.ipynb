{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all the requirements with:\n",
    "! sudo apt-get install libboost-dev libboost-serialization-dev \\\n",
    "gdal-bin libgdal-dev make cmake libbz2-dev libexpat1-dev swig\n",
    "\n",
    "#! sudo apt-get install libboost-dev libboost-serialization-dev \\\n",
    "#gdal-bin libgdal-dev make cmake libbz2-dev libexpat1-dev swig python-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/cyang-kth/fmm.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!! This could take ~ 6 mintues !!!!\n",
    "# it may not work and requires for password, etc.\n",
    "# in this case, go to your folder using console to compile and install FMM\n",
    "\n",
    "import os\n",
    "# change working directory\n",
    "os.chdir(\"fmm\")\n",
    "\n",
    "if not os.path.exists('build'):\n",
    "  os.mkdir('build')\n",
    "# ! mkdir build\n",
    "os.chdir(\"build\")\n",
    "# ! cd build\n",
    "! cmake ..\n",
    "! make -j4\n",
    "! sudo make install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import time\n",
    "from shapely.geometry import Polygon\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def save_graph_shapefile_directional(G, filepath=None, encoding=\"utf-8\"):\n",
    "    # default filepath if none was provided\n",
    "    if filepath is None:\n",
    "        filepath = os.path.join(ox.settings.data_folder, \"graph_shapefile\")\n",
    "\n",
    "    # if save folder does not already exist, create it (shapefiles\n",
    "    # get saved as set of files)\n",
    "    if not filepath == \"\" and not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "    filepath_nodes = os.path.join(filepath, \"nodes.shp\")\n",
    "    filepath_edges = os.path.join(filepath, \"edges.shp\")\n",
    "\n",
    "    # convert undirected graph to gdfs and stringify non-numeric columns\n",
    "    gdf_nodes, gdf_edges = ox.utils_graph.graph_to_gdfs(G)\n",
    "    gdf_nodes = ox.io._stringify_nonnumeric_cols(gdf_nodes)\n",
    "    gdf_edges = ox.io._stringify_nonnumeric_cols(gdf_edges)\n",
    "\n",
    "    # We need an unique ID for each edge\n",
    "    gdf_edges[\"fid\"] = np.arange(0, gdf_edges.shape[0], dtype='int')\n",
    "\n",
    "    # save the nodes and edges as separate ESRI shapefiles\n",
    "    gdf_nodes.to_file(filepath_nodes, encoding=encoding)\n",
    "    gdf_edges.to_file(filepath_edges, encoding=encoding)\n",
    "\n",
    "print(\"osmnx version\",ox.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place =\"Porto, Portugal\"\n",
    "\n",
    "start_time = time.time()\n",
    "G = ox.graph_from_place(place, network_type='drive', which_result=2)\n",
    "\n",
    "save_graph_shapefile_directional(G, filepath='/content/data/porto')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "ox.plot_graph(G)\n",
    "ox.save_graphml(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "from fmm import (\n",
    "    Network,\n",
    "    NetworkGraph,\n",
    "    UBODTGenAlgorithm,\n",
    "    UBODT,\n",
    "    FastMapMatch,\n",
    "    FastMapMatchConfig,\n",
    "    STMATCH,\n",
    "    STMATCHConfig\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Set up paths to save to Google Drive\n",
    "google_drive_path = '/content/drive/My Drive'  # Adjust if your Google Drive path is different\n",
    "\n",
    "data_dir = '/content/data'\n",
    "\n",
    "save_dir = os.path.join(google_drive_path, 'data')\n",
    "\n",
    "# Ensure the data directory exists\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Paths to your data and output files in Google Drive\n",
    "network_file_path = os.path.join(data_dir, \"porto\", \"edges.shp\")\n",
    "ubodt_file_path = os.path.join(data_dir, \"ubodt.txt\")\n",
    "train_csv_path = os.path.join(data_dir, \"train-1500-cleaned.csv\")\n",
    "output_csv_path = os.path.join(save_dir, \"matched-results-1500_cleaned.csv\")\n",
    "\n",
    "# Read network data\n",
    "network = Network(network_file_path, \"fid\", \"u\", \"v\")\n",
    "print(\"Nodes {} edges {}\".format(network.get_node_count(), network.get_edge_count()))\n",
    "graph = NetworkGraph(network)\n",
    "\n",
    "# Precompute an UBODT table\n",
    "if os.path.isfile(ubodt_file_path):\n",
    "    ubodt = UBODT.read_ubodt_csv(ubodt_file_path)\n",
    "    print(\"Read the ubodt file\")\n",
    "else:\n",
    "    print(\"Generate and read the ubodt file\")\n",
    "    ubodt_gen = UBODTGenAlgorithm(network, graph)\n",
    "    status = ubodt_gen.generate_ubodt(ubodt_file_path, 0.03, binary=False, use_omp=True)\n",
    "    print(f\"UBODT Generation Status: {status}\")\n",
    "    ubodt = UBODT.read_ubodt_csv(ubodt_file_path)\n",
    "\n",
    "# Create FMM model\n",
    "fmm_model = FastMapMatch(network, graph, ubodt)\n",
    "\n",
    "# Define map matching configurations for FMM\n",
    "k = 16\n",
    "radius = 0.005\n",
    "gps_error = 0.0005\n",
    "fmm_config = FastMapMatchConfig(k, radius, gps_error)\n",
    "\n",
    "# Create STMATCH model\n",
    "stmatch_model = STMATCH(network, graph)\n",
    "\n",
    "# Define STMATCH map matching configurations\n",
    "k_stmatch = 8\n",
    "radius_stmatch = 0.05\n",
    "gps_error_stmatch = 0.005\n",
    "vmax = 0.003\n",
    "factor = 1.5\n",
    "stmatch_config = STMATCHConfig(k_stmatch, radius_stmatch, gps_error_stmatch, vmax, factor)\n",
    "\n",
    "# Read trajectory data from CSV\n",
    "train1500 = []\n",
    "with open(train_csv_path, \"r\", newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        polyline_str = row.get(\"POLYLINE\")\n",
    "        if polyline_str:\n",
    "            try:\n",
    "                row[\"POLYLINE\"] = json.loads(polyline_str)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Invalid POLYLINE format in row {row}\")\n",
    "                row[\"POLYLINE\"] = []\n",
    "        else:\n",
    "            row[\"POLYLINE\"] = []\n",
    "        train1500.append(row)\n",
    "\n",
    "\n",
    "for i, trajectory in enumerate(train1500):\n",
    "    polyline = trajectory[\"POLYLINE\"]\n",
    "    if not polyline:\n",
    "        print(f\"Empty POLYLINE for trajectory index {i}\")\n",
    "        continue\n",
    "\n",
    "    # Convert polyline to WKT format\n",
    "    wkt = \"LINESTRING(\" + \",\".join([\"{} {}\".format(point[0], point[1]) for point in polyline]) + \")\"\n",
    "\n",
    "    # Try FMM\n",
    "    result = fmm_model.match_wkt(wkt, fmm_config)\n",
    "    train1500[i][\"MATCHING_ALGORITHM\"] = \"fmm\"\n",
    "\n",
    "    if not list(result.cpath):\n",
    "        # Try STMATCH if FMM fails\n",
    "        result = stmatch_model.match_wkt(wkt, stmatch_config)\n",
    "        train1500[i][\"MATCHING_ALGORITHM\"] = \"stmatch\"\n",
    "        if not list(result.cpath):\n",
    "            print(f\"No match found for trajectory index {i}, WKT: {wkt}\")\n",
    "            continue  # Skip to next trajectory if no match found\n",
    "\n",
    "    # Adding matched results according to your output field specifications\n",
    "    train1500[i][\"MATCHED_RESULTS\"] = {\n",
    "        \"id\": i,\n",
    "        \"ogeom\": wkt,\n",
    "        \"opath\": list(result.opath),\n",
    "        \"error\": [c.error for c in result.candidates],\n",
    "        \"offset\": [c.offset for c in result.candidates],\n",
    "        \"length\": [c.length for c in result.candidates],\n",
    "        \"spdist\": [c.spdist for c in result.candidates],\n",
    "        \"duration\": [0] * len(result.candidates),  # Placeholder, replace with actual duration if available\n",
    "        \"speed\": [0] * len(result.candidates),  # Placeholder, replace with actual speed if available\n",
    "        \"pgeom\": result.pgeom.export_wkt(),\n",
    "        \"cpath\": list(result.cpath),\n",
    "        \"tpath\": list(result.indices),\n",
    "        \"mgeom\": result.mgeom.export_wkt(),\n",
    "        \"ep\": [c.ep for c in result.candidates],\n",
    "        \"tp\": [c.tp for c in result.candidates],\n",
    "        \"matching_algorithm\": train1500[i][\"MATCHING_ALGORITHM\"],\n",
    "        \"eid\": [c.edge_id for c in result.candidates],\n",
    "        \"source\": [c.source for c in result.candidates],\n",
    "        \"target\": [c.target for c in result.candidates]\n",
    "    }\n",
    "    print(f\"Processed trajectory index {i}\")\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "output_dir = os.path.dirname(output_csv_path)\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define CSV headers based on the modified field names\n",
    "headers = [\"id\", \"ogeom\", \"opath\", \"error\", \"offset\", \"length\", \"spdist\", \"duration\", \"speed\",\n",
    "           \"pgeom\", \"cpath\", \"tpath\", \"mgeom\", \"ep\", \"tp\", \"MATCHING_ALGORITHM\", \"eid\", \"source\", \"target\"]\n",
    "\n",
    "with open(output_csv_path, \"w\", newline='') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for trajectory in train1500:  \n",
    "        if \"MATCHED_RESULTS\" in trajectory:\n",
    "            matched_results = trajectory[\"MATCHED_RESULTS\"]\n",
    "            flattened_row = {\n",
    "                \"id\": matched_results[\"id\"],\n",
    "                \"ogeom\": matched_results[\"ogeom\"],\n",
    "                \"opath\": json.dumps(matched_results[\"opath\"]),\n",
    "                \"error\": json.dumps(matched_results[\"error\"]),\n",
    "                \"offset\": json.dumps(matched_results[\"offset\"]),\n",
    "                \"length\": json.dumps(matched_results[\"length\"]),\n",
    "                \"spdist\": json.dumps(matched_results[\"spdist\"]),\n",
    "                \"duration\": json.dumps(matched_results[\"duration\"]),\n",
    "                \"speed\": json.dumps(matched_results[\"speed\"]),\n",
    "                \"pgeom\": matched_results[\"pgeom\"],\n",
    "                \"cpath\": json.dumps(matched_results[\"cpath\"]),\n",
    "                \"tpath\": json.dumps(matched_results[\"tpath\"]),\n",
    "                \"mgeom\": matched_results[\"mgeom\"],\n",
    "                \"ep\": json.dumps(matched_results[\"ep\"]),\n",
    "                \"tp\": json.dumps(matched_results[\"tp\"]),\n",
    "                \"MATCHING_ALGORITHM\": matched_results[\"matching_algorithm\"],\n",
    "                \"eid\": json.dumps(matched_results[\"eid\"]),\n",
    "                \"source\": json.dumps(matched_results[\"source\"]),\n",
    "                \"target\": json.dumps(matched_results[\"target\"])\n",
    "            }\n",
    "            writer.writerow(flattened_row)\n",
    "\n",
    "print(f\"Results saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing geometry: IllegalArgumentException: point array must contain 0 or >1 elements\n",
      "\n",
      "Error parsing geometry: IllegalArgumentException: point array must contain 0 or >1 elements\n",
      "\n",
      "Individual map for Trip 1 saved to data/Task6\\fmap_route_1.html\n",
      "Individual map for Trip 2 saved to data/Task6\\fmap_route_2.html\n",
      "Individual map for Trip 3 saved to data/Task6\\fmap_route_3.html\n",
      "Individual map for Trip 4 saved to data/Task6\\fmap_route_4.html\n",
      "Individual map for Trip 5 saved to data/Task6\\fmap_route_5.html\n",
      "Individual map for Trip 6 saved to data/Task6\\fmap_route_6.html\n",
      "Individual map for Trip 7 saved to data/Task6\\fmap_route_7.html\n",
      "Individual map for Trip 8 saved to data/Task6\\fmap_route_8.html\n",
      "Individual map for Trip 9 saved to data/Task6\\fmap_route_9.html\n",
      "Individual map for Trip 10 saved to data/Task6\\fmap_route_10.html\n",
      "Individual map for Trip 11 saved to data/Task6\\fmap_route_11.html\n",
      "Individual map for Trip 12 saved to data/Task6\\fmap_route_12.html\n",
      "Individual map for Trip 13 saved to data/Task6\\fmap_route_13.html\n",
      "Individual map for Trip 14 saved to data/Task6\\fmap_route_14.html\n",
      "Individual map for Trip 15 saved to data/Task6\\fmap_route_15.html\n",
      "Combined map saved to data\\Mapped_task6.html\n",
      "Visualization completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import folium\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from shapely.geometry import LineString\n",
    "import os\n",
    "\n",
    "def parse_mgeom(value):\n",
    "    \"\"\"Parse LINESTRING format into a LineString object.\"\"\"\n",
    "    try:\n",
    "        if value.startswith(\"LINESTRING\"):\n",
    "            coords = value.replace(\"LINESTRING(\", \"\").replace(\")\", \"\").split(\",\")\n",
    "            coords = [(float(coord.split()[0]), float(coord.split()[1])) for coord in coords]\n",
    "            return LineString(coords)\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing geometry: {e}\")\n",
    "        return None\n",
    "\n",
    "def calculate_boundaries(current_x_max, current_y_max, current_x_min, current_y_min, is_first, longitude, latitude):\n",
    "    if is_first:\n",
    "        current_x_min = current_x_max = longitude\n",
    "        current_y_min = current_y_max = latitude\n",
    "        is_first = False\n",
    "    else:\n",
    "        current_x_max = max(current_x_max, longitude)\n",
    "        current_x_min = min(current_x_min, longitude)\n",
    "        current_y_max = max(current_y_max, latitude)\n",
    "        current_y_min = min(current_y_min, latitude)\n",
    "    return current_x_max, current_y_max, current_x_min, current_y_min, is_first\n",
    "\n",
    "def visualize_routes(file_path, save_combined=True, save_individual=True, plot_lines=True, plot_points=True):\n",
    "    \"\"\"\n",
    "    Visualize the first 15 routes from the CSV file by creating a combined map and individual maps.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): Path to the CSV file containing route data.\n",
    "    - save_combined (bool): Whether to save the combined map.\n",
    "    - save_individual (bool): Whether to save individual maps for each route.\n",
    "    - plot_lines (bool): Whether to plot lines between points in the routes.\n",
    "    - plot_points (bool): Whether to plot individual points in the routes.\n",
    "    \"\"\"\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return\n",
    "\n",
    "    # Load and parse geometries\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['geometry'] = df['mgeom'].apply(parse_mgeom)\n",
    "    df = df.dropna(subset=['geometry'])\n",
    "    if df.empty:\n",
    "        print(\"No valid geometries found.\")\n",
    "        return\n",
    "\n",
    "    # Initialize boundaries and color mapping for routes\n",
    "    current_x_max = current_y_max = current_x_min = current_y_min = None\n",
    "    is_first = True\n",
    "    num_routes = min(15, len(df))\n",
    "    colors = plt.cm.jet(np.linspace(0, 1, num_routes))\n",
    "\n",
    "    # Calculate boundaries based on route data\n",
    "    for i, geometry in enumerate(df['geometry'].head(num_routes)):\n",
    "        x, y = geometry.xy\n",
    "        for lon, lat in zip(x, y):\n",
    "            current_x_max, current_y_max, current_x_min, current_y_min, is_first = calculate_boundaries(\n",
    "                current_x_max, current_y_max, current_x_min, current_y_min, is_first, lon, lat\n",
    "            )\n",
    "\n",
    "    # Adjust boundaries with padding for the map view\n",
    "    if is_first:\n",
    "        # Default boundaries if no points were processed\n",
    "        current_x_min, current_x_max = -8.7, -8.5  \n",
    "        current_y_min, current_y_max = 41.1, 41.3\n",
    "    else:\n",
    "        x_padding = (current_x_max - current_x_min) * 0.05\n",
    "        y_padding = (current_y_max - current_y_min) * 0.05\n",
    "        current_x_min -= x_padding\n",
    "        current_x_max += x_padding\n",
    "        current_y_min -= y_padding\n",
    "        current_y_max += y_padding\n",
    "\n",
    "    # Generate a color list in hex format for consistency with Folium\n",
    "    colors_hex = [\n",
    "        f'#{int(color[0]*255):02x}{int(color[1]*255):02x}{int(color[2]*255):02x}'\n",
    "        for color in colors\n",
    "    ]\n",
    "\n",
    "    # Directory to save individual route maps\n",
    "    individual_dir = 'data/Task6'\n",
    "    if not os.path.exists(individual_dir):\n",
    "        os.makedirs(individual_dir)\n",
    "\n",
    "    # Create a combined Folium map if required\n",
    "    if save_combined:\n",
    "        combined_map = folium.Map(\n",
    "            location=[(current_y_max + current_y_min) / 2, (current_x_max + current_x_min) / 2],\n",
    "            zoom_start=13,\n",
    "            # tiles=\"cartodbpositron\",\n",
    "            max_bounds=True\n",
    "        )\n",
    "        combined_map.fit_bounds([[current_y_min, current_x_min], [current_y_max, current_x_max]])\n",
    "\n",
    "    # Iterate through each route to add to the combined map and save individually\n",
    "    for idx, geometry in enumerate(df['geometry'].head(num_routes)):\n",
    "        lcoord = list(zip(*geometry.xy))  # Convert LineString to list of coordinates (lon, lat)\n",
    "        lcoord = [(lat, lon) for lon, lat in lcoord]  # Convert to (lat, lon) tuples for Folium\n",
    "        color = colors_hex[idx]\n",
    "\n",
    "        # Add to combined map\n",
    "        if save_combined:\n",
    "            feature_group = folium.FeatureGroup(name=f'Trip {idx + 1}')\n",
    "\n",
    "            # Add polyline for the route if plot_lines is enabled\n",
    "            if plot_lines:\n",
    "                folium.PolyLine(\n",
    "                    locations=lcoord,\n",
    "                    color=color,\n",
    "                    weight=3,\n",
    "                    opacity=0.7\n",
    "                ).add_to(feature_group)\n",
    "\n",
    "            # Add circle markers for each point if plot_points is enabled\n",
    "            if plot_points:\n",
    "                for point in lcoord:\n",
    "                    folium.CircleMarker(\n",
    "                        location=point,\n",
    "                        radius=3,\n",
    "                        color=color,\n",
    "                        fill=True,\n",
    "                        fill_color=color,\n",
    "                        fill_opacity=1\n",
    "                    ).add_to(feature_group)\n",
    "\n",
    "            # Highlight start and end points\n",
    "            folium.CircleMarker(\n",
    "                location=lcoord[0],\n",
    "                radius=5,\n",
    "                color='green',\n",
    "                fill=True,\n",
    "                fill_color='green',\n",
    "                fill_opacity=1,\n",
    "                tooltip=f'Start Trip {idx + 1}'\n",
    "            ).add_to(feature_group)\n",
    "\n",
    "            folium.CircleMarker(\n",
    "                location=lcoord[-1],\n",
    "                radius=5,\n",
    "                color='red',\n",
    "                fill=True,\n",
    "                fill_color='red',\n",
    "                fill_opacity=1,\n",
    "                tooltip=f'End Trip {idx + 1}'\n",
    "            ).add_to(feature_group)\n",
    "\n",
    "            feature_group.add_to(combined_map)\n",
    "\n",
    "        # Save individual map\n",
    "        if save_individual:\n",
    "            # Create a Folium map centered on the route's first point\n",
    "            individual_map = folium.Map(\n",
    "                location=[lcoord[0][0], lcoord[0][1]],\n",
    "                zoom_start=14,\n",
    "                # tiles=\"cartodbpositron\"\n",
    "            )\n",
    "\n",
    "            # Adjust map bounds to fit the route\n",
    "            latitudes = [point[0] for point in lcoord]\n",
    "            longitudes = [point[1] for point in lcoord]\n",
    "            bounds = [[min(latitudes), min(longitudes)], [max(latitudes), max(longitudes)]]\n",
    "            individual_map.fit_bounds(bounds)\n",
    "\n",
    "            # Create a feature group for the current route\n",
    "            individual_fg = folium.FeatureGroup(name=f'Trip {idx + 1}')\n",
    "\n",
    "            # Add polyline for the route if plot_lines is enabled\n",
    "            if plot_lines:\n",
    "                folium.PolyLine(\n",
    "                    locations=lcoord,\n",
    "                    color=color,\n",
    "                    weight=3,\n",
    "                    opacity=0.7\n",
    "                ).add_to(individual_fg)\n",
    "\n",
    "            # Add circle markers for each point if plot_points is enabled\n",
    "            if plot_points:\n",
    "                for point in lcoord:\n",
    "                    folium.CircleMarker(\n",
    "                        location=point,\n",
    "                        radius=3,\n",
    "                        color=color,\n",
    "                        fill=True,\n",
    "                        fill_color=color,\n",
    "                        fill_opacity=1\n",
    "                    ).add_to(individual_fg)\n",
    "\n",
    "            # Highlight start and end points\n",
    "            folium.CircleMarker(\n",
    "                location=lcoord[0],\n",
    "                radius=5,\n",
    "                color='green',\n",
    "                fill=True,\n",
    "                fill_color='green',\n",
    "                fill_opacity=1,\n",
    "                tooltip=f'Start Trip {idx + 1}'\n",
    "            ).add_to(individual_fg)\n",
    "\n",
    "            folium.CircleMarker(\n",
    "                location=lcoord[-1],\n",
    "                radius=5,\n",
    "                color='red',\n",
    "                fill=True,\n",
    "                fill_color='red',\n",
    "                fill_opacity=1,\n",
    "                tooltip=f'End Trip {idx + 1}'\n",
    "            ).add_to(individual_fg)\n",
    "\n",
    "            # Add feature group to the individual map\n",
    "            individual_fg.add_to(individual_map)\n",
    "\n",
    "            # Add layer control (optional for individual maps)\n",
    "            folium.LayerControl().add_to(individual_map)\n",
    "\n",
    "            # Define output path for individual map\n",
    "            individual_output_path = os.path.join(individual_dir, f'fmap_route_{idx + 1}.html')\n",
    "            individual_map.save(individual_output_path)\n",
    "            print(f\"Individual map for Trip {idx + 1} saved to {individual_output_path}\")\n",
    "\n",
    "    # Finalize and save the combined map\n",
    "    if save_combined:\n",
    "        # Add layer control to the combined map\n",
    "        folium.LayerControl().add_to(combined_map)\n",
    "\n",
    "        # Define output path for combined map\n",
    "        combined_output_dir = 'data'\n",
    "        if not os.path.exists(combined_output_dir):\n",
    "            os.makedirs(combined_output_dir)\n",
    "        combined_output_path = os.path.join(combined_output_dir, 'Mapped_task6.html')\n",
    "        combined_map.save(combined_output_path)\n",
    "        print(f\"Combined map saved to {combined_output_path}\")\n",
    "\n",
    "    print(\"Visualization completed successfully.\")\n",
    "\n",
    "# Run the function with the specified file path\n",
    "visualize_routes(\n",
    "    file_path=\"data/matched_results_1500_cleaned.csv\",\n",
    "    save_combined=True,      \n",
    "    save_individual=True,    \n",
    "    plot_lines=True,         \n",
    "    plot_points=True         \n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
