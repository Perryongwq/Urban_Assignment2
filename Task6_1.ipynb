{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folium and Data Processing Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import osmnx as ox\n",
    "from fmm import (\n",
    "    Network,\n",
    "    NetworkGraph,\n",
    "    UBODTGenAlgorithm,\n",
    "    UBODT,\n",
    "    FastMapMatch,\n",
    "    FastMapMatchConfig,\n",
    "    STMATCH,\n",
    "    STMATCHConfig,\n",
    ")\n",
    "import folium\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors  # Import for rgb2hex\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "# Additional Import for JSON handling\n",
    "import json\n",
    "\n",
    "# Suppress warnings from osmnx\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define the paths to your network data and UBODT file\n",
    "folder = '/content/data'  # Update this to your folder path\n",
    "network_file_path = os.path.join(folder, \"porto\", \"edges.shp\")\n",
    "ubodt_file_path = os.path.join(folder, \"ubodt.txt\")\n",
    "\n",
    "\n",
    "def load_graph(bounds):\n",
    "    \"\"\"\n",
    "    Create the street network within the bounding box.\n",
    "\n",
    "    Args:\n",
    "        bounds (tuple): A tuple containing the bounding box coordinates (x1, x2, y1, y2).\n",
    "\n",
    "    Returns:\n",
    "        networkx.MultiDiGraph: The street network graph.\n",
    "    \"\"\"\n",
    "    x1, x2, y1, y2 = bounds\n",
    "    boundary_polygon = Polygon([(x1, y1), (x2, y1), (x2, y2), (x1, y2)])\n",
    "    return ox.graph_from_polygon(boundary_polygon, network_type='drive')\n",
    "\n",
    "\n",
    "def load_data(file_path, nrows=None):\n",
    "    \"\"\"\n",
    "    Load the trajectory data from a CSV file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file.\n",
    "        nrows (int, optional): Number of rows to read. Defaults to None (all rows).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Loaded DataFrame.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(file_path, nrows=nrows)\n",
    "\n",
    "\n",
    "def clean_trajectory_data(df):\n",
    "    \"\"\"\n",
    "    Convert trajectory data from string to NumPy arrays.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing trajectory data.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array with cleaned trajectory data.\n",
    "    \"\"\"\n",
    "    train_data = df.to_numpy()\n",
    "\n",
    "    for i in range(len(train_data)):\n",
    "        # Extract the trajectory string from column 8 (0-based index)\n",
    "        traj_str = train_data[i, 8]\n",
    "        # Remove leading/trailing characters and split by comma\n",
    "        data = traj_str[2:-2].replace(']', '').replace('[', '').split(',')\n",
    "\n",
    "        if len(data) > 1:\n",
    "            try:\n",
    "                data = np.asarray(data, dtype=float).reshape((len(data) // 2, 2))\n",
    "            except ValueError:\n",
    "                # Handle cases where data cannot be reshaped properly\n",
    "                data = np.asarray([[0.0, 0.0]])\n",
    "        else:\n",
    "            data = np.asarray([[0.0, 0.0]])\n",
    "\n",
    "        train_data[i, 8] = data\n",
    "\n",
    "    return train_data\n",
    "\n",
    "\n",
    "def remove_outliers(train_data, threshold_multiplier=5):\n",
    "    \"\"\"\n",
    "    Remove outlying GPS coordinates based on a distance threshold.\n",
    "\n",
    "    Args:\n",
    "        train_data (np.ndarray): Array containing trajectory data.\n",
    "        threshold_multiplier (float, optional): Multiplier for the average distance to determine outliers. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array with outliers removed.\n",
    "    \"\"\"\n",
    "    for i in range(len(train_data)):\n",
    "        GPS_trajectory = train_data[i, 8]\n",
    "        num_points = len(GPS_trajectory)\n",
    "\n",
    "        if num_points > 1:\n",
    "            route_dist = 0.0\n",
    "            # Calculate the total route distance\n",
    "            for j in range(num_points - 1):\n",
    "                lon_1, lat_1 = GPS_trajectory[j]\n",
    "                lon_2, lat_2 = GPS_trajectory[j + 1]\n",
    "                route_dist += np.linalg.norm([lon_1 - lon_2, lat_1 - lat_2])\n",
    "\n",
    "            ave_dist = route_dist / (num_points - 1)\n",
    "            j = 0\n",
    "\n",
    "            # Compare points and remove outliers\n",
    "            while j < (len(GPS_trajectory) - 1):\n",
    "                lon_1, lat_1 = GPS_trajectory[j]\n",
    "                lon_2, lat_2 = GPS_trajectory[j + 1]\n",
    "                dist = np.linalg.norm([lon_1 - lon_2, lat_1 - lat_2])\n",
    "\n",
    "                if dist > threshold_multiplier * ave_dist:\n",
    "                    GPS_trajectory = np.delete(GPS_trajectory, j + 1, 0)\n",
    "                    if j > 0:\n",
    "                        j -= 1  # Move back one step to re-evaluate after deletion\n",
    "                else:\n",
    "                    j += 1  # Move to the next point\n",
    "\n",
    "            train_data[i, 8] = GPS_trajectory\n",
    "\n",
    "    return train_data\n",
    "\n",
    "\n",
    "def save_cleaned_data(train_data, original_df, output_path):\n",
    "    \"\"\"\n",
    "    Save the cleaned train_data back to a CSV file in the original format.\n",
    "\n",
    "    Args:\n",
    "        train_data (np.ndarray): The cleaned trajectory data.\n",
    "        original_df (pd.DataFrame): The original DataFrame loaded from the CSV.\n",
    "        output_path (str): The path where the cleaned CSV will be saved.\n",
    "    \"\"\"\n",
    "    # Create a copy of the original DataFrame to maintain all columns\n",
    "    cleaned_df = original_df.copy()\n",
    "\n",
    "    # Convert the NumPy arrays back to string format for column 8\n",
    "    cleaned_df.iloc[:, 8] = [str(traj.tolist()) for traj in train_data[:, 8]]\n",
    "\n",
    "    # Save the cleaned DataFrame to a new CSV file\n",
    "    cleaned_df.to_csv(output_path, index=False)\n",
    "    print(f\"Cleaned data saved to {output_path}\")\n",
    "\n",
    "\n",
    "def load_cleaned_data(cleaned_file_path):\n",
    "    \"\"\"\n",
    "    Load the cleaned CSV file and convert trajectory strings back to NumPy arrays.\n",
    "\n",
    "    Args:\n",
    "        cleaned_file_path (str): Path to the cleaned CSV file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_data_cleaned as np.ndarray, cleaned_df as pd.DataFrame)\n",
    "    \"\"\"\n",
    "    cleaned_df = pd.read_csv(cleaned_file_path)\n",
    "    train_data_cleaned = cleaned_df.to_numpy()\n",
    "\n",
    "    for i in range(len(train_data_cleaned)):\n",
    "        # Extract the trajectory string from column 8\n",
    "        traj_str = train_data_cleaned[i, 8]\n",
    "        # Remove leading/trailing characters and split by comma\n",
    "        data = traj_str[2:-2].replace(']', '').replace('[', '').split(',')\n",
    "\n",
    "        if len(data) > 1:\n",
    "            try:\n",
    "                data = np.asarray(data, dtype=float).reshape((len(data) // 2, 2))\n",
    "            except ValueError:\n",
    "                # Handle cases where data cannot be reshaped properly\n",
    "                data = np.asarray([[0.0, 0.0]])\n",
    "        else:\n",
    "            data = np.asarray([[0.0, 0.0]])\n",
    "\n",
    "        train_data_cleaned[i, 8] = data\n",
    "\n",
    "    return train_data_cleaned, cleaned_df\n",
    "\n",
    "\n",
    "def plot_trajectories_folium(G, train_data, traj_indices, output_path, title='Trajectories'):\n",
    "    \"\"\"\n",
    "    Plot the trajectories using Folium.\n",
    "\n",
    "    Args:\n",
    "        G (networkx.MultiDiGraph): The street network graph.\n",
    "        train_data (np.ndarray): Array containing trajectory data.\n",
    "        traj_indices (list): List of indices of trajectories to plot.\n",
    "        output_path (str): Path to save the Folium HTML map.\n",
    "        title (str, optional): Title of the plot. Defaults to 'Trajectories'.\n",
    "    \"\"\"\n",
    "    # Calculate map boundaries\n",
    "    all_lons = []\n",
    "    all_lats = []\n",
    "    for traj_idx in traj_indices:\n",
    "        traj = train_data[traj_idx, 8]\n",
    "        if isinstance(traj, np.ndarray):\n",
    "            all_lons.extend(traj[:, 0])\n",
    "            all_lats.extend(traj[:, 1])\n",
    "\n",
    "    if not all_lons or not all_lats:\n",
    "        raise ValueError(\"No valid trajectories to plot.\")\n",
    "\n",
    "    x_min, x_max = min(all_lons), max(all_lons)\n",
    "    y_min, y_max = min(all_lats), max(all_lats)\n",
    "    map_center = [(y_min + y_max) / 2, (x_min + x_max) / 2]\n",
    "\n",
    "    # Initialize Folium map\n",
    "    folium_map = folium.Map(location=map_center, zoom_start=14, control_scale=True)\n",
    "\n",
    "    # Fit map to bounds\n",
    "    folium_map.fit_bounds([[y_min, x_min], [y_max, x_max]])\n",
    "\n",
    "    # Generate a color map with a specific number of colors\n",
    "    num_traj = len(traj_indices)  # Number of trajectories\n",
    "    color_map = plt.get_cmap('tab10')(np.linspace(0, 1, num_traj))  # Use np.linspace to sample the colormap\n",
    "\n",
    "    # Plot each trajectory using Folium\n",
    "    for i, traj_idx in enumerate(traj_indices):\n",
    "        traj = train_data[traj_idx, 8]\n",
    "        if isinstance(traj, np.ndarray) and len(traj) > 1:\n",
    "            # Convert to list of [lat, lon] pairs for Folium\n",
    "            traj_coords = traj[:, [1, 0]].tolist()  # Folium expects [lat, lon]\n",
    "            folium.PolyLine(\n",
    "                traj_coords,\n",
    "                color=mcolors.rgb2hex(color_map[i]),  # Use mcolors.rgb2hex\n",
    "                weight=5,\n",
    "                opacity=0.8,\n",
    "                tooltip=f'Trip {traj_idx + 1}'\n",
    "            ).add_to(folium_map)\n",
    "\n",
    "            # Add green marker for the start (first point)\n",
    "            start_point = traj[0]\n",
    "            folium.Marker(\n",
    "                location=[start_point[1], start_point[0]],  # [lat, lon]\n",
    "                icon=folium.Icon(color='green', icon='circle'),\n",
    "                popup=f\"Start of Trip {traj_idx + 1}\"\n",
    "            ).add_to(folium_map)\n",
    "\n",
    "            # Add red marker for the end (last point)\n",
    "            end_point = traj[-1]\n",
    "            folium.Marker(\n",
    "                location=[end_point[1], end_point[0]],  # [lat, lon]\n",
    "                icon=folium.Icon(color='red', icon='circle'),\n",
    "                popup=f\"End of Trip {traj_idx + 1}\"\n",
    "            ).add_to(folium_map)\n",
    "\n",
    "    # Add a legend\n",
    "    legend_html = '''\n",
    "     <div style=\"\n",
    "     position: fixed;\n",
    "     bottom: 50px; left: 50px; width: 150px; height: auto;\n",
    "     background-color: white; z-index:9999; font-size:14px;\n",
    "     border:2px solid grey;\n",
    "     padding: 10px;\n",
    "     \">\n",
    "         <p style=\"margin: 0;\"><b>Legend</b></p>\n",
    "         <ul style=\"list-style: none; padding-left: 0;\">\n",
    "    '''\n",
    "    for i, traj_idx in enumerate(traj_indices):\n",
    "        color_hex = mcolors.rgb2hex(color_map[i])  # Corrected hex conversion\n",
    "        legend_html += f'<li><span style=\"background-color:{color_hex};width:20px;height:5px;display:inline-block;margin-right:5px;\"></span> Trip {traj_idx + 1}</li>'\n",
    "    legend_html += '</ul></div>'\n",
    "\n",
    "    folium_map.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "    # Add Layer Control\n",
    "    folium.LayerControl().add_to(folium_map)\n",
    "\n",
    "    # Save the map to an HTML file\n",
    "    folium_map.save(output_path)\n",
    "    print(f\"Interactive Folium map saved to {output_path}\")\n",
    "\n",
    "\n",
    "def prepare_fmm_data(train_data):\n",
    "    \"\"\"\n",
    "    Prepare the data for FastMapMatch.\n",
    "\n",
    "    Args:\n",
    "        train_data (np.ndarray): Array containing trajectory data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame formatted for FMM.\n",
    "    \"\"\"\n",
    "    input_data = []\n",
    "    for i in range(len(train_data)):\n",
    "        trajectory = train_data[i, 8]\n",
    "        if isinstance(trajectory, np.ndarray):\n",
    "            trajectory_str = ','.join([f\"{coord[0]} {coord[1]}\" for coord in trajectory.tolist()])\n",
    "            trajectory_wkt = f\"LINESTRING({trajectory_str})\"\n",
    "        else:\n",
    "            trajectory_wkt = \"LINESTRING(0 0, 0 0)\"  # Default if trajectory is invalid\n",
    "        input_data.append({'id': train_data[i, 0], 'geom': trajectory_wkt})\n",
    "\n",
    "    return pd.DataFrame(input_data)\n",
    "\n",
    "\n",
    "def map_matching(input_data, network, graph, ubodt, fmm_config):\n",
    "    \"\"\"\n",
    "    Perform Map Matching using FastMapMatch.\n",
    "\n",
    "    Args:\n",
    "        input_data (pd.DataFrame): DataFrame containing 'id' and 'geom' columns.\n",
    "        network (Network): The network data.\n",
    "        graph (NetworkGraph): The network graph.\n",
    "        ubodt (UBODT): The UBODT data.\n",
    "        fmm_config (FastMapMatchConfig): Configuration for FMM.\n",
    "\n",
    "    Returns:\n",
    "        list: List of flattened match results.\n",
    "    \"\"\"\n",
    "    model = FastMapMatch(network, graph, ubodt)\n",
    "    results = []\n",
    "\n",
    "    for idx, geom in enumerate(input_data['geom'].values):\n",
    "        try:\n",
    "            result = model.match_wkt(geom, fmm_config)\n",
    "            \n",
    "            # Assuming 'result' has an attribute or method to access \"MATCHED_RESULTS\"\n",
    "            # This part may need adjustment based on the actual structure of 'result'\n",
    "            # For demonstration, assuming 'result' has a 'MATCHED_RESULTS' attribute\n",
    "            if hasattr(result, \"MATCHED_RESULTS\"):\n",
    "                matched_results = result.MATCHED_RESULTS\n",
    "                flattened_row = {\n",
    "                    \"id\": matched_results[\"id\"],\n",
    "                    \"ogeom\": matched_results[\"ogeom\"],\n",
    "                    \"opath\": json.dumps(matched_results[\"opath\"]),\n",
    "                    \"error\": json.dumps(matched_results[\"error\"]),\n",
    "                    \"offset\": json.dumps(matched_results[\"offset\"]),\n",
    "                    \"length\": json.dumps(matched_results[\"length\"]),\n",
    "                    \"spdist\": json.dumps(matched_results[\"spdist\"]),\n",
    "                    \"duration\": json.dumps(matched_results.get(\"duration\", [])),  # Use .get to handle missing keys\n",
    "                    \"speed\": json.dumps(matched_results.get(\"speed\", [])),\n",
    "                    \"pgeom\": matched_results[\"pgeom\"],\n",
    "                    \"cpath\": json.dumps(matched_results[\"cpath\"]),\n",
    "                    \"tpath\": json.dumps(matched_results[\"tpath\"]),\n",
    "                    \"mgeom\": matched_results[\"mgeom\"],\n",
    "                    \"ep\": json.dumps(matched_results[\"ep\"]),\n",
    "                    \"tp\": json.dumps(matched_results[\"tp\"]),\n",
    "                    \"MATCHING_ALGORITHM\": matched_results[\"matching_algorithm\"],\n",
    "                    \"eid\": json.dumps(matched_results[\"eid\"]),\n",
    "                    \"source\": json.dumps(matched_results[\"source\"]),\n",
    "                    \"target\": json.dumps(matched_results[\"target\"])\n",
    "                }\n",
    "                results.append(flattened_row)\n",
    "            else:\n",
    "                # Handle cases where \"MATCHED_RESULTS\" is not in the result\n",
    "                print(f\"No MATCHED_RESULTS in trajectory for index {idx}\")\n",
    "                results.append(None)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Map matching failed for index {idx}: {e}\")\n",
    "            results.append(None)  # Append None or handle as needed\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def plot_map_matching_folium(G, results, traj_indices, output_path, title='Map Matching Results'):\n",
    "    \"\"\"\n",
    "    Plot the map-matched trajectories using Folium.\n",
    "\n",
    "    Args:\n",
    "        G (networkx.MultiDiGraph): The street network graph.\n",
    "        results (list): List of map matching results.\n",
    "        traj_indices (list): List of trajectory indices to plot.\n",
    "        output_path (str): Path to save the Folium HTML map.\n",
    "        title (str, optional): Title of the plot. Defaults to 'Map Matching Results'.\n",
    "    \"\"\"\n",
    "    # Extract matched geometries and calculate map boundaries\n",
    "    all_lons = []\n",
    "    all_lats = []\n",
    "    matched_trajs = {}\n",
    "\n",
    "    for traj_idx in traj_indices:\n",
    "        if traj_idx < len(results) and results[traj_idx] and \"mgeom\" in results[traj_idx]:\n",
    "            mgeom = results[traj_idx][\"mgeom\"]\n",
    "            if mgeom.startswith('LINESTRING'):\n",
    "                coords = mgeom.replace('LINESTRING(', '').replace(')', '').split(',')\n",
    "                traj_coords = []\n",
    "                for coord in coords:\n",
    "                    try:\n",
    "                        lon, lat = map(float, coord.strip().split())\n",
    "                        traj_coords.append([lat, lon])\n",
    "                        all_lons.append(lon)\n",
    "                        all_lats.append(lat)\n",
    "                    except ValueError:\n",
    "                        # Log invalid coordinate or skip if there's an issue\n",
    "                        print(f\"Skipping invalid coordinate: {coord.strip()}\")\n",
    "                        continue\n",
    "                if traj_coords:\n",
    "                    matched_trajs[traj_idx] = traj_coords\n",
    "\n",
    "    if not all_lons or not all_lats:\n",
    "        raise ValueError(\"No valid map-matched trajectories to plot.\")\n",
    "\n",
    "    x_min, x_max = min(all_lons), max(all_lons)\n",
    "    y_min, y_max = min(all_lats), max(all_lats)\n",
    "    map_center = [(y_min + y_max) / 2, (x_min + x_max) / 2]\n",
    "\n",
    "    # Initialize Folium map\n",
    "    folium_map = folium.Map(location=map_center, zoom_start=14, control_scale=True)\n",
    "\n",
    "    # Fit map to bounds\n",
    "    folium_map.fit_bounds([[y_min, x_min], [y_max, x_max]])\n",
    "\n",
    "    # Generate a color map with a specific number of colors\n",
    "    num_traj = len(traj_indices)  # Number of trajectories\n",
    "    color_map = plt.get_cmap('tab10')(np.linspace(0, 1, num_traj))  # Use np.linspace to sample the colormap\n",
    "\n",
    "    # Plot each map-matched trajectory\n",
    "    for i, traj_idx in enumerate(traj_indices):\n",
    "        traj = matched_trajs.get(traj_idx, [])\n",
    "        if traj:\n",
    "            folium.PolyLine(\n",
    "                traj,\n",
    "                color=mcolors.rgb2hex(color_map[i]),  # Corrected hex conversion\n",
    "                weight=5,\n",
    "                opacity=0.8,\n",
    "                tooltip=f'Match Trip {traj_idx + 1}'\n",
    "            ).add_to(folium_map)\n",
    "\n",
    "    # Add a legend\n",
    "    legend_html = '''\n",
    "     <div style=\"\n",
    "     position: fixed;\n",
    "     bottom: 50px; left: 50px; width: 150px; height: auto;\n",
    "     background-color: white; z-index:9999; font-size:14px;\n",
    "     border:2px solid grey;\n",
    "     padding: 10px;\n",
    "     \">\n",
    "         <p style=\"margin: 0;\"><b>Legend</b></p>\n",
    "         <ul style=\"list-style: none; padding-left: 0;\">\n",
    "    '''\n",
    "    for i, traj_idx in enumerate(traj_indices):\n",
    "        color_hex = mcolors.rgb2hex(color_map[i])  # Corrected hex conversion\n",
    "        legend_html += f'<li><span style=\"background-color:{color_hex};width:20px;height:5px;display:inline-block;margin-right:5px;\"></span> Match Trip {traj_idx + 1}</li>'\n",
    "    legend_html += '</ul></div>'\n",
    "\n",
    "    folium_map.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "    # Add Layer Control\n",
    "    folium.LayerControl().add_to(folium_map)\n",
    "\n",
    "    # Save the map to an HTML file\n",
    "    folium_map.save(output_path)\n",
    "    print(f\"Interactive Folium map with map matching saved to {output_path}\")\n",
    "\n",
    "\n",
    "def generate_ubodt(network_file_path, ubodt_file_path):\n",
    "    \"\"\"\n",
    "    Generate UBODT if it does not exist.\n",
    "\n",
    "    Args:\n",
    "        network_file_path (str): Path to the network shapefile.\n",
    "        ubodt_file_path (str): Path to save the UBODT file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (ubodt, network, graph)\n",
    "    \"\"\"\n",
    "    # Ensure the network file exists\n",
    "    if not os.path.exists(network_file_path):\n",
    "        raise FileNotFoundError(f\"Network file not found: {network_file_path}\")\n",
    "\n",
    "    # Read the network data\n",
    "    network = Network(network_file_path, \"fid\", \"u\", \"v\")\n",
    "    graph = NetworkGraph(network)\n",
    "\n",
    "    # Check if UBODT file exists\n",
    "    if os.path.isfile(ubodt_file_path):\n",
    "        ubodt = UBODT.read_ubodt_csv(ubodt_file_path)\n",
    "        print(\"Read the UBODT file\")\n",
    "    else:\n",
    "        print(\"Generating UBODT file...\")\n",
    "        # Generate the UBODT using the UBODTGenAlgorithm\n",
    "        ubodt_gen = UBODTGenAlgorithm(network, graph)\n",
    "        status = ubodt_gen.generate_ubodt(ubodt_file_path, 0.03, binary=False, use_omp=True)\n",
    "        print(f\"UBODT Generation Status: {status}\")\n",
    "\n",
    "        # After generating the UBODT, load it\n",
    "        ubodt = UBODT.read_ubodt_csv(ubodt_file_path)\n",
    "        print(\"UBODT file generated and loaded.\")\n",
    "\n",
    "    return ubodt, network, graph  # Return UBODT, Network, and Graph\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to execute the data cleaning and FastMapMatch process.\n",
    "    \"\"\"\n",
    "    # Define bounding box: (x1, x2, y1, y2)\n",
    "    bounds = (-8.70, -8.57, 41.13, 41.19)  # Corrected y1 and y2 to be in increasing order\n",
    "\n",
    "    # Define file paths\n",
    "    train_file = os.path.join(folder, \"train-1500.csv\")\n",
    "    cleaned_train_file = os.path.join(folder, \"train-1500-cleaned.csv\")  # Path for cleaned data\n",
    "    output_dir = '/content/data/'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    output_file = os.path.join(output_dir, 'Trajectories_Before_Outlier_Removal_Folium.html')\n",
    "    outlier_file = os.path.join(output_dir, 'Trajectories_After_Outlier_Removal_Folium.html')\n",
    "    fmm_output_file = os.path.join(output_dir, 'Trajectories_After_FMM_Folium.html')\n",
    "    trips_csv = os.path.join(output_dir, 'trips2.csv')\n",
    "\n",
    "    # Generate UBODT and get network and graph\n",
    "    ubodt, network, graph = generate_ubodt(network_file_path, ubodt_file_path)\n",
    "\n",
    "    # Load graph and data\n",
    "    G = load_graph(bounds)\n",
    "    df = load_data(train_file, nrows=1500)  # Load first 1500 rows of the dataset\n",
    "\n",
    "    # Clean trajectory data\n",
    "    train_data = clean_trajectory_data(df)\n",
    "\n",
    "    # Select the top 15 trajectories (can be based on any criterion, here just the first 15)\n",
    "    traj_indices = list(range(15))  # Select first 15 trajectories\n",
    "\n",
    "    # Plot initial trips before outlier removal\n",
    "    plot_trajectories_folium(\n",
    "        G,\n",
    "        train_data,\n",
    "        traj_indices,\n",
    "        output_file,\n",
    "        title='Top 15 Trajectories Before Outlier Removal'\n",
    "    )\n",
    "\n",
    "    # Remove outliers\n",
    "    train_data = remove_outliers(train_data)\n",
    "\n",
    "    # Plot trips after removing outliers\n",
    "    plot_trajectories_folium(\n",
    "        G,\n",
    "        train_data,\n",
    "        traj_indices,\n",
    "        outlier_file,\n",
    "        title='Top 15 Trajectories After Outlier Removal'\n",
    "    )\n",
    "\n",
    "    # Save the cleaned data to a new CSV file\n",
    "    save_cleaned_data(train_data, df, cleaned_train_file)\n",
    "\n",
    "    # Load the cleaned data for FMM\n",
    "    train_data_cleaned, clean_df = load_cleaned_data(cleaned_train_file)\n",
    "\n",
    "    # Prepare data for FMM\n",
    "    input_data = prepare_fmm_data(train_data_cleaned)\n",
    "    input_data.to_csv(trips_csv, index=False, sep=';')\n",
    "    print(f\"Prepared FMM data saved to {trips_csv}\")\n",
    "\n",
    "    # Map Matching with FMM\n",
    "    fmm_config = FastMapMatchConfig(16, 0.005, 0.0005)  # Adjust parameters as needed\n",
    "    results = map_matching(input_data, network, graph, ubodt, fmm_config)\n",
    "    print(\"Map matching completed.\")\n",
    "    \n",
    "    # Convert results to DataFrame, excluding None entries\n",
    "    matched_df = pd.DataFrame([res for res in results if res is not None])\n",
    "    \n",
    "    # Save matched results to a CSV file\n",
    "    matched_results_file = os.path.join(output_dir, 'matched_results.csv')\n",
    "    matched_df.to_csv(matched_results_file, index=False)\n",
    "    print(f\"Matched results saved to {matched_results_file}\")\n",
    "    \n",
    "    # Plot Map Matching results\n",
    "    plot_map_matching_folium(\n",
    "        G,\n",
    "        results,\n",
    "        traj_indices,\n",
    "        fmm_output_file,\n",
    "        title='Top 15 Map Matching Results'\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
