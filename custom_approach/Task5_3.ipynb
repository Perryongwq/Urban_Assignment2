{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import osmnx as ox\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString, box\n",
    "import networkx as nx\n",
    "from dataclasses import dataclass\n",
    "import ast\n",
    "import rtree\n",
    "import logging\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from math import pi\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "from folium.features import DivIcon\n",
    "from branca.colormap import LinearColormap\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "SIGMA_Z = 15.0  # Increased sigma_z for more tolerance in emission\n",
    "MAX_DISTANCE = 50.0  # Increased max_distance for broader candidate search\n",
    "TURN_ANGLE_THRESHOLD = pi / 4  # 45 degrees threshold for transition penalty\n",
    "MIN_TRANSITION_PROB = 1e-5  # Non-zero transition probability for flexibility\n",
    "\n",
    "class EnhancedViterbiMatcher:\n",
    "    def __init__(self, graph, edges_gdf, config=None):\n",
    "        \"\"\"Initialize matcher with improved configuration\"\"\"\n",
    "        self.graph = graph\n",
    "        self.edges_gdf = edges_gdf.copy()\n",
    "        \n",
    "        if isinstance(self.edges_gdf.index, pd.MultiIndex):\n",
    "            self.edges_gdf = self.edges_gdf.reset_index(drop=True)\n",
    "        self.edges_gdf.index = range(len(self.edges_gdf))\n",
    "        \n",
    "        # Enhanced default configuration\n",
    "        default_config = {\n",
    "            'max_candidates': 20,          # Increased from 10\n",
    "            'max_distance': 100.0,         # Increased from 50.0\n",
    "            'sigma_z': 50.0,              # Adjusted for better GPS noise handling\n",
    "            'beta': 2.0,                  # Increased for better transition scoring\n",
    "            'min_prob_norm': 1e-7,        # Lowered for more flexibility\n",
    "            'max_speed': 50.0,            # Maximum expected speed (m/s)\n",
    "            'min_speed': 0.1,             # Minimum expected speed (m/s)\n",
    "            'angle_tolerance': np.pi/2,    # 90 degrees angle tolerance\n",
    "            'max_angle_penalty': 0.5,      # Maximum penalty for sharp turns\n",
    "            'distance_decay': 0.85,        # Distance decay factor\n",
    "            'sequential_matching': True    # Enable sequential matching for long trajectories\n",
    "        }\n",
    "        \n",
    "        if config:\n",
    "            default_config.update(config)\n",
    "        self.config = default_config\n",
    "        \n",
    "        self._init_spatial_index()\n",
    "        self.edge_to_nodes = self._build_edge_to_nodes()\n",
    "        self.node_to_edges = self._build_node_to_edges()\n",
    "        \n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    def _init_spatial_index(self):\n",
    "        \"\"\"Initialize R-tree spatial index with improved error handling\"\"\"\n",
    "        try:\n",
    "            self.spatial_index = rtree.index.Index()\n",
    "            for idx, edge in self.edges_gdf.iterrows():\n",
    "                if edge.geometry is not None and not edge.geometry.is_empty:\n",
    "                    self.spatial_index.insert(idx, edge.geometry.bounds)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error initializing spatial index: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _build_edge_to_nodes(self) -> Dict[int, set]:\n",
    "        \"\"\"Build mapping from edge IDs to their endpoint nodes with validation\"\"\"\n",
    "        edge_to_nodes = {}\n",
    "        for idx, edge in self.edges_gdf.iterrows():\n",
    "            if edge.geometry is not None and not edge.geometry.is_empty:\n",
    "                coords = list(edge.geometry.coords)\n",
    "                if len(coords) >= 2:  # Ensure valid linestring\n",
    "                    edge_to_nodes[idx] = {\n",
    "                        self._get_node_id(coords[0]),\n",
    "                        self._get_node_id(coords[-1])\n",
    "                    }\n",
    "        return edge_to_nodes\n",
    "\n",
    "    def _build_node_to_edges(self) -> Dict[tuple, set]:\n",
    "        \"\"\"Build mapping from nodes to connected edge IDs\"\"\"\n",
    "        node_to_edges = {}\n",
    "        for edge_id, nodes in self.edge_to_nodes.items():\n",
    "            for node in nodes:\n",
    "                if node not in node_to_edges:\n",
    "                    node_to_edges[node] = set()\n",
    "                node_to_edges[node].add(edge_id)\n",
    "        return node_to_edges\n",
    "\n",
    "    def _get_node_id(self, coord: tuple) -> tuple:\n",
    "        \"\"\"Convert coordinate to node ID with improved precision\"\"\"\n",
    "        return tuple(round(x, 6) for x in coord)\n",
    "\n",
    "    def _find_candidates(self, point: Point) -> List[dict]:\n",
    "        \"\"\"Enhanced candidate finding with adaptive search radius\"\"\"\n",
    "        candidates = []\n",
    "        initial_distance = 30.0  # Start with a reduced search radius\n",
    "        max_attempts = 3\n",
    "        current_distance = initial_distance\n",
    "        \n",
    "        for attempt in range(max_attempts):\n",
    "            bounds = (\n",
    "                point.x - current_distance,\n",
    "                point.y - current_distance,\n",
    "                point.x + current_distance,\n",
    "                point.y + current_distance\n",
    "            )\n",
    "            \n",
    "            for idx in self.spatial_index.intersection(bounds):\n",
    "                edge = self.edges_gdf.loc[idx]\n",
    "                if edge.geometry is not None:\n",
    "                    dist = point.distance(edge.geometry)\n",
    "                    if dist <= current_distance:\n",
    "                        proj_point = edge.geometry.interpolate(\n",
    "                            edge.geometry.project(point)\n",
    "                        )\n",
    "                        candidates.append({\n",
    "                            'edge_id': idx,\n",
    "                            'distance': dist,\n",
    "                            'proj_point': proj_point,\n",
    "                            'edge': edge\n",
    "                        })\n",
    "            \n",
    "            if candidates:\n",
    "                break\n",
    "                \n",
    "            current_distance *= 1.5  # Increase search radius for next attempt\n",
    "        \n",
    "        candidates.sort(key=lambda x: x['distance'])\n",
    "        return candidates[:self.config['max_candidates']]\n",
    "\n",
    "    def _calculate_emission_prob(self, point: Point, candidate: dict) -> float:\n",
    "        \"\"\"Enhanced emission probability calculation with improved scaling\"\"\"\n",
    "        distance = candidate['distance']\n",
    "        sigma_z = self.config['sigma_z']\n",
    "        \n",
    "        # Distance-based probability with decay\n",
    "        distance_factor = np.exp(-distance * self.config['distance_decay'])\n",
    "        \n",
    "        # Gaussian probability\n",
    "        gaussian_prob = np.exp(-0.5 * (distance / sigma_z) ** 2)\n",
    "        \n",
    "        # Combined probability\n",
    "        prob = gaussian_prob * distance_factor\n",
    "        \n",
    "        return max(prob, self.config['min_prob_norm'])\n",
    "\n",
    "    def _calculate_transition_prob(self, prev_edge: int, curr_edge: int,\n",
    "                                 prev_point: Point, curr_point: Point) -> float:\n",
    "        \"\"\"Enhanced transition probability with improved angle handling\"\"\"\n",
    "        prev_nodes = self.edge_to_nodes[prev_edge]\n",
    "        curr_nodes = self.edge_to_nodes[curr_edge]\n",
    "        \n",
    "        connected = bool(prev_nodes.intersection(curr_nodes))\n",
    "        connectivity_score = 1.0 if connected else 0.3\n",
    "        \n",
    "        dir1 = np.array(prev_point.coords[-1]) - np.array(prev_point.coords[0])\n",
    "        dir2 = np.array(curr_point.coords[-1]) - np.array(curr_point.coords[0])\n",
    "        \n",
    "        norm1 = np.linalg.norm(dir1)\n",
    "        norm2 = np.linalg.norm(dir2)\n",
    "        \n",
    "        if norm1 == 0 or norm2 == 0:\n",
    "            angle_score = 1.0\n",
    "        else:\n",
    "            cos_angle = np.dot(dir1, dir2) / (norm1 * norm2)\n",
    "            angle = np.arccos(np.clip(cos_angle, -1.0, 1.0))\n",
    "            \n",
    "            angle_score = 1.0 - (angle / self.config['angle_tolerance']) * self.config['max_angle_penalty']\n",
    "            angle_score = max(angle_score, 1.0 - self.config['max_angle_penalty'])\n",
    "        \n",
    "        prob = connectivity_score * angle_score\n",
    "        return max(prob, self.config['min_prob_norm'])\n",
    "\n",
    "    def _viterbi_matching(self, points: List[Point], candidates_by_point: List[List[dict]]) -> List[Dict]:\n",
    "        \"\"\"Improved Viterbi algorithm with better numerical stability\"\"\"\n",
    "        n_points = len(points)\n",
    "        states = [{} for _ in range(n_points)]\n",
    "        \n",
    "        # Initialize first state\n",
    "        for candidate in candidates_by_point[0]:\n",
    "            edge_id = candidate['edge_id']\n",
    "            log_emission = np.log(self._calculate_emission_prob(points[0], candidate))\n",
    "            states[0][edge_id] = {\n",
    "                'log_prob': log_emission,\n",
    "                'prev': None,\n",
    "                'emission': log_emission,\n",
    "                'transition': 0.0\n",
    "            }\n",
    "        \n",
    "        # Forward pass with log probabilities\n",
    "        for t in range(1, n_points):\n",
    "            for candidate in candidates_by_point[t]:\n",
    "                curr_edge = candidate['edge_id']\n",
    "                log_emission = np.log(self._calculate_emission_prob(points[t], candidate))\n",
    "                \n",
    "                best_log_prob = float('-inf')\n",
    "                best_prev = None\n",
    "                best_transition = None\n",
    "                \n",
    "                for prev_edge, prev_state in states[t-1].items():\n",
    "                    trans_prob = self._calculate_transition_prob(\n",
    "                        prev_edge, curr_edge, points[t-1], points[t]\n",
    "                    )\n",
    "                    log_transition = np.log(trans_prob)\n",
    "                    \n",
    "                    log_prob = prev_state['log_prob'] + log_transition + log_emission\n",
    "                    \n",
    "                    if log_prob > best_log_prob:\n",
    "                        best_log_prob = log_prob\n",
    "                        best_prev = prev_edge\n",
    "                        best_transition = log_transition\n",
    "                \n",
    "                if best_prev is not None:\n",
    "                    states[t][curr_edge] = {\n",
    "                        'log_prob': best_log_prob,\n",
    "                        'prev': best_prev,\n",
    "                        'emission': log_emission,\n",
    "                        'transition': best_transition\n",
    "                    }\n",
    "        \n",
    "        # Convert log probabilities to normalized confidence scores\n",
    "        if states[-1]:\n",
    "            log_probs = np.array([state['log_prob'] for state in states[-1].values()])\n",
    "            max_log_prob = np.max(log_probs)\n",
    "            normalized_probs = np.exp(log_probs - max_log_prob)\n",
    "            normalized_probs /= np.sum(normalized_probs)\n",
    "            \n",
    "            for edge_id, norm_prob in zip(states[-1].keys(), normalized_probs):\n",
    "                states[-1][edge_id]['confidence'] = norm_prob\n",
    "        \n",
    "        return states\n",
    "\n",
    "    def _backtrack(self, states: List[Dict]) -> List[int]:\n",
    "        \"\"\"Backtrack to find the best path with improved handling of edge cases\"\"\"\n",
    "        if not states or not states[-1]:\n",
    "            return []\n",
    "        \n",
    "        path = []\n",
    "        current_edge = max(states[-1].items(), key=lambda x: x[1]['log_prob'])[0]\n",
    "        \n",
    "        for t in range(len(states) - 1, -1, -1):\n",
    "            path.append(current_edge)\n",
    "            if t > 0 and states[t][current_edge]['prev'] is not None:\n",
    "                current_edge = states[t][current_edge]['prev']\n",
    "        \n",
    "        return list(reversed(path))\n",
    "\n",
    "    def _sequential_matching(self, points: List[Point]) -> Dict:\n",
    "        \"\"\"Match long trajectories in sequential segments with overlap\"\"\"\n",
    "        segment_size = 30\n",
    "        overlap = 10\n",
    "        all_edges = []\n",
    "        segment_confidences = []\n",
    "        \n",
    "        for i in range(0, len(points), segment_size - overlap):\n",
    "            segment = points[i:i + segment_size]\n",
    "            if len(segment) < 2:\n",
    "                continue\n",
    "                \n",
    "            candidates = [self._find_candidates(p) for p in segment]\n",
    "            if not all(candidates):\n",
    "                continue\n",
    "                \n",
    "            states = self._viterbi_matching(segment, candidates)\n",
    "            path = self._backtrack(states)\n",
    "            \n",
    "            if path:\n",
    "                if states[-1] and path[-1] in states[-1]:\n",
    "                    segment_confidences.append(states[-1][path[-1]].get('confidence', 0.0))\n",
    "                    \n",
    "                if all_edges and overlap > 0:\n",
    "                    all_edges = all_edges[:-overlap]\n",
    "                all_edges.extend(path)\n",
    "        \n",
    "        if not all_edges:\n",
    "            return {'success': False, 'edges': [], 'confidence': 0.0}\n",
    "        \n",
    "        overall_confidence = np.mean(segment_confidences) if segment_confidences else 0.0\n",
    "            \n",
    "        return {\n",
    "            'success': True,\n",
    "            'edges': all_edges,\n",
    "            'confidence': overall_confidence\n",
    "        }\n",
    "\n",
    "    def match_trajectory(self, points: List[Tuple[float, float]]) -> Dict:\n",
    "        \"\"\"Match trajectory with improved error handling and validation\"\"\"\n",
    "        try:\n",
    "            if len(points) < 2:\n",
    "                return {'success': False, 'edges': [], 'confidence': 0.0}\n",
    "\n",
    "            point_objects = [Point(p) for p in points]\n",
    "            \n",
    "            if self.config['sequential_matching'] and len(points) > 50:\n",
    "                return self._sequential_matching(point_objects)\n",
    "            \n",
    "            candidates_by_point = [self._find_candidates(p) for p in point_objects]\n",
    "            \n",
    "            if not all(candidates_by_point):\n",
    "                return {'success': False, 'edges': [], 'confidence': 0.0}\n",
    "            \n",
    "            states = self._viterbi_matching(point_objects, candidates_by_point)\n",
    "            path = self._backtrack(states)\n",
    "            \n",
    "            if not path:\n",
    "                return {'success': False, 'edges': [], 'confidence': 0.0}\n",
    "            \n",
    "            confidence = states[-1][path[-1]].get('confidence', 0.0)\n",
    "            \n",
    "            return {\n",
    "                'success': True,\n",
    "                'edges': path,\n",
    "                'confidence': confidence\n",
    "            }\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in match_trajectory: {str(e)}\")\n",
    "            return {'success': False, 'edges': [], 'confidence': 0.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_identifier(edge_data) -> str:\n",
    "    \"\"\"Get a unique identifier for an edge, falling back to alternatives if OSMID is not available\"\"\"\n",
    "    if 'OSMID' in edge_data:\n",
    "        return str(edge_data['OSMID'])\n",
    "    elif 'osmid' in edge_data:  # Try lowercase version\n",
    "        return str(edge_data['osmid'])\n",
    "    elif 'name' in edge_data:\n",
    "        return f\"road_{edge_data['name']}\"\n",
    "    else:\n",
    "        # Create a unique identifier from the edge geometry\n",
    "        coords = list(edge_data.geometry.coords)\n",
    "        start = coords[0]\n",
    "        end = coords[-1]\n",
    "        return f\"edge_{start[0]:.4f}_{start[1]:.4f}_{end[0]:.4f}_{end[1]:.4f}\"\n",
    "\n",
    "class RouteAnalyzer:\n",
    "    \"\"\"Analyze mapped routes for frequently traversed and slow segments\"\"\"\n",
    "    def __init__(self, matcher, matched_results: List[Dict], output_dir: str = 'map_matching_results'):\n",
    "        self.matcher = matcher\n",
    "        self.matched_results = matched_results\n",
    "        self.output_dir = output_dir\n",
    "        self.analysis_dir = os.path.join(output_dir, 'route_analysis')\n",
    "        os.makedirs(self.analysis_dir, exist_ok=True)\n",
    "        \n",
    "        # Convert edges to WGS84 for visualization\n",
    "        self.edges_wgs84 = matcher.edges_gdf.to_crs('EPSG:4326')\n",
    "        \n",
    "        # Initialize segment statistics\n",
    "        self.segment_stats = self._initialize_segment_stats()\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _initialize_segment_stats(self) -> Dict:\n",
    "        \"\"\"Initialize statistics for each road segment with improved validation\"\"\"\n",
    "        stats = {}\n",
    "        \n",
    "        for result in self.matched_results:\n",
    "            if not result['match_result']['success']:\n",
    "                continue\n",
    "            \n",
    "            coords = result['original_coords']\n",
    "            edges = result['match_result']['edges']\n",
    "            timestamps = result['timestamps']\n",
    "            \n",
    "            if len(coords) < 2 or not edges or timestamps is None:\n",
    "                continue\n",
    "            \n",
    "            for edge_id in edges:\n",
    "                if edge_id not in stats:\n",
    "                    edge_data = self.matcher.edges_gdf.loc[edge_id]\n",
    "                    road_id = get_edge_identifier(edge_data)\n",
    "                    \n",
    "                    stats[edge_id] = {\n",
    "                        'traverse_count': 0,\n",
    "                        'OSMID': road_id,\n",
    "                        'length': 0,\n",
    "                        'speeds': [],\n",
    "                        'times': [],\n",
    "                        'distance_traversed': 0\n",
    "                    }\n",
    "                \n",
    "                edge_geom = self.matcher.edges_gdf.loc[edge_id].geometry\n",
    "                stats[edge_id]['length'] = edge_geom.length\n",
    "                stats[edge_id]['distance_traversed'] += edge_geom.length\n",
    "                \n",
    "                speed, time = self._analyze_trajectory_segment(\n",
    "                    edge_id, \n",
    "                    edge_geom, \n",
    "                    coords,\n",
    "                    timestamps\n",
    "                )\n",
    "                \n",
    "                # Only add valid speed/time measurements\n",
    "                if speed > 0 and time > 0:\n",
    "                    stats[edge_id]['traverse_count'] += 1\n",
    "                    stats[edge_id]['speeds'].append(speed)\n",
    "                    stats[edge_id]['times'].append(time)\n",
    "        \n",
    "        # Calculate aggregate statistics with validation\n",
    "        for edge_id, edge_stats in stats.items():\n",
    "            if edge_stats['traverse_count'] > 0 and edge_stats['speeds']:\n",
    "                valid_speeds = [s for s in edge_stats['speeds'] if s > 0]\n",
    "                if valid_speeds:\n",
    "                    edge_stats['avg_speed'] = np.mean(valid_speeds)\n",
    "                    edge_stats['speed_std'] = np.std(valid_speeds) if len(valid_speeds) > 1 else 0\n",
    "                    edge_stats['avg_time'] = np.mean([t for t in edge_stats['times'] if t > 0])\n",
    "                    edge_stats['congestion_index'] = (edge_stats['speed_std'] / edge_stats['avg_speed'] \n",
    "                                                if edge_stats['avg_speed'] > 0 else 0)\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def _analyze_trajectory_segment(self, edge_id: int, edge_geom, coords: List[tuple], \n",
    "                            timestamps: List[int]) -> tuple:\n",
    "        \"\"\"Analyze trajectory segment with speed in m/s\"\"\"\n",
    "        edge_length = edge_geom.length\n",
    "        if len(coords) < 2 or len(timestamps) < 2:\n",
    "            return 0, 0\n",
    "\n",
    "        # Calculate time difference in seconds\n",
    "        time_diffs = [timestamps[i+1] - timestamps[i] for i in range(len(timestamps) - 1)]\n",
    "        total_time = sum(time_diffs)\n",
    "\n",
    "        # Validate time and length\n",
    "        if total_time <= 0 or edge_length <= 0:\n",
    "            return 0, 0\n",
    "        \n",
    "        # Calculate speed (m/s)\n",
    "        speed = edge_length / total_time\n",
    "        \n",
    "        total_time = edge_length / speed\n",
    "        \n",
    "        # # Validate speed is realistic\n",
    "        # min_speed_ms = 0.3  # ≈1 km/h in m/s\n",
    "        # max_speed_ms = 33.3  # ≈120 km/h in m/s\n",
    "        \n",
    "        # if speed < min_speed_ms:\n",
    "        #     speed = min_speed_ms\n",
    "        #     total_time = edge_length / min_speed_ms\n",
    "        # elif speed > max_speed_ms:\n",
    "        #     speed = max_speed_ms\n",
    "        #     total_time = edge_length / max_speed_ms\n",
    "        \n",
    "        return speed, total_time\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_most_traversed_segments(self, n: int = 10) -> List[Dict]:\n",
    "        \"\"\"Return the n most frequently traversed road segments\"\"\"\n",
    "        segments = []\n",
    "        for edge_id, stats in self.segment_stats.items():\n",
    "            if stats['traverse_count'] > 0:\n",
    "                segments.append({\n",
    "                    'edge_id': edge_id,\n",
    "                    'OSMID': stats['OSMID'],\n",
    "                    'count': stats['traverse_count'],\n",
    "                    'geometry': self.edges_wgs84.loc[edge_id].geometry,\n",
    "                    'avg_speed': stats.get('avg_speed', 0),\n",
    "                    'avg_time': stats.get('avg_time', 0),\n",
    "                    'length': stats['length'],\n",
    "                    'speed_std': stats.get('speed_std', 0),\n",
    "                    'congestion_index': stats.get('congestion_index', 0),\n",
    "                    'distance_traversed': stats['distance_traversed']\n",
    "                })\n",
    "        \n",
    "        segments.sort(key=lambda x: x['count'], reverse=True)\n",
    "        return segments[:n]\n",
    "    \n",
    "    def get_slowest_segments(self, n: int = 10) -> List[Dict]:\n",
    "        \"\"\"Return the n slowest road segments with speed in m/s\"\"\"\n",
    "        segments = []\n",
    "        min_length = 50  # Only consider segments longer than 50m\n",
    "        min_speed = 0.3  # Minimum realistic speed in m/s (≈1 km/h)\n",
    "        max_speed = 33.3  # Maximum realistic speed in m/s (≈120 km/h)\n",
    "        \n",
    "        for edge_id, stats in self.segment_stats.items():\n",
    "            if (stats['traverse_count'] > 0 and \n",
    "                stats.get('avg_time', 0) > 0 and \n",
    "                stats['length'] >= min_length):\n",
    "                \n",
    "                # Calculate speed in m/s\n",
    "                speed_ms = stats['length'] / stats['avg_time']\n",
    "                \n",
    "                # Validate speed is realistic\n",
    "                if speed_ms >= min_speed and speed_ms <= max_speed:\n",
    "                    segments.append({\n",
    "                        'edge_id': edge_id,\n",
    "                        'OSMID': stats['OSMID'],\n",
    "                        'avg_time': stats['avg_time'],\n",
    "                        'count': stats['traverse_count'],\n",
    "                        'geometry': self.edges_wgs84.loc[edge_id].geometry,\n",
    "                        'length': stats['length'],\n",
    "                        'speed_ms': speed_ms,\n",
    "                        'time_per_100m': (stats['avg_time'] / stats['length']) * 100\n",
    "                    })\n",
    "        \n",
    "        # Sort by speed (lower speed = slower segment)\n",
    "        segments.sort(key=lambda x: x['speed_ms'])\n",
    "        return segments[:n]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def _get_metric_display(self, segment: Dict, metric_name: str) -> str:\n",
    "        \"\"\"Format metric display for legend with m/s speed and time metrics\"\"\"\n",
    "        if 'traverse' in metric_name.lower():\n",
    "            return f\"Count: {segment['count']}\"\n",
    "        else:\n",
    "            # Calculate time metrics\n",
    "            time_minutes = segment['avg_time'] / 60\n",
    "            time_per_100m = (segment['avg_time'] / segment['length']) * 100\n",
    "            \n",
    "            return (f\"Speed: {segment['speed_ms']:.1f} m/s\\n\"\n",
    "                    f\"Length: {segment['length']:.0f}m\\n\"\n",
    "                    f\"Time: {time_minutes:.1f} min\\n\"\n",
    "                    f\"Time/100m: {time_per_100m:.1f} sec\")\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    def _create_popup_text(self, segment: Dict, rank: int) -> str:\n",
    "        \"\"\"Create detailed popup text for segment\"\"\"\n",
    "        return f\"\"\"\n",
    "        <div style='font-family: Arial; font-size: 12px;'>\n",
    "            <strong>Rank: {rank}</strong><br>\n",
    "            OSMID: {segment['OSMID']}<br>\n",
    "            Edge ID: {segment['edge_id']}<br>\n",
    "            Traverse count: {segment['num_traversals']}<br>\n",
    "            Average Speed: {segment['avg_speed_kmh']:.1f} km/h<br>\n",
    "            Time per 100m: {segment['time_per_100m']:.1f} seconds<br>\n",
    "            Length: {segment['length']:.0f} m<br>\n",
    "            Total traversal time: {segment['total_time']:.0f} seconds\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "    def _create_title_html(self, title: str, num_segments: int, metric_name: str) -> str:\n",
    "        \"\"\"Create enhanced HTML for map title\"\"\"\n",
    "        return f\"\"\"\n",
    "        <div style=\"\n",
    "            position: fixed;\n",
    "            top: 20px;\n",
    "            left: 60px;\n",
    "            width: 320px;\n",
    "            z-index: 1000;\n",
    "            padding: 15px;\n",
    "            background-color: white;\n",
    "            border-radius: 6px;\n",
    "            box-shadow: 0 2px 5px rgba(0,0,0,0.2);\n",
    "        \">\n",
    "            <h3 style=\"margin: 0; color: #2c3e50;\">{title}</h3>\n",
    "            <p style=\"margin: 8px 0 0 0; font-size: 13px; color: #666;\">\n",
    "                Showing top {num_segments} segments ranked by {metric_name.lower()}\n",
    "            </p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def visualize_segments_enhanced(self, segments: List[Dict], title: str, filename: str,\n",
    "                          metric_name: str, color_scheme: List[str]):\n",
    "        \"\"\"Create enhanced interactive visualization with corrected colormap scaling\"\"\"\n",
    "        if not segments:\n",
    "            logging.warning(f\"No segments to visualize for {title}\")\n",
    "            return\n",
    "        \n",
    "        # Create base map\n",
    "        center_lat, center_lon = 41.1579, -8.6291  # Porto coordinates\n",
    "        m = folium.Map(\n",
    "            location=[center_lat, center_lon],\n",
    "            zoom_start=13,\n",
    "            tiles='cartodbpositron'\n",
    "        )\n",
    "        \n",
    "        # Add background network\n",
    "        for _, edge in self.edges_wgs84.iterrows():\n",
    "            if edge.geometry is not None:\n",
    "                coords = [(y, x) for x, y in edge.geometry.coords]\n",
    "                folium.PolyLine(\n",
    "                    coords,\n",
    "                    weight=1,\n",
    "                    color='lightgray',\n",
    "                    opacity=0.1\n",
    "                ).add_to(m)\n",
    "        \n",
    "        if segments:\n",
    "            # Calculate proper metric values for colormap with rounding\n",
    "            if 'average travel time' in metric_name.lower():\n",
    "                # Round time_per_100m values to 1 decimal place\n",
    "                metric_values = [round(seg['time_per_100m'], 1) for seg in segments]\n",
    "                caption = 'Time per 100m (seconds)'\n",
    "                \n",
    "                # Update vmin and vmax with rounded values\n",
    "                vmin = min(metric_values)\n",
    "                vmax = max(metric_values)\n",
    "                \n",
    "                # Create colormap with rounded range\n",
    "                colormap = LinearColormap(\n",
    "                    colors=color_scheme,\n",
    "                    vmin=vmin,\n",
    "                    vmax=vmax,\n",
    "                    caption=f\"{vmin:.1f} - {vmax:.1f} {caption}\"\n",
    "                )\n",
    "            else:\n",
    "                # For traverse count, keep as integers\n",
    "                metric_values = [seg['count'] for seg in segments]\n",
    "                caption = 'Traverse Count'\n",
    "                colormap = LinearColormap(\n",
    "                    colors=color_scheme,\n",
    "                    vmin=min(metric_values),\n",
    "                    vmax=max(metric_values),\n",
    "                    caption=caption\n",
    "                )\n",
    "            \n",
    "            # Create legend\n",
    "            legend_html = \"\"\"\n",
    "            <div style=\"\n",
    "                position: fixed;\n",
    "                bottom: 50px;\n",
    "                right: 50px;\n",
    "                width: 250px;\n",
    "                z-index: 1000;\n",
    "                background-color: white;\n",
    "                padding: 10px;\n",
    "                border-radius: 5px;\n",
    "                box-shadow: 0 0 5px rgba(0,0,0,0.2);\n",
    "                font-size: 12px;\n",
    "                max-height: 300px;\n",
    "                overflow-y: auto;\n",
    "            \">\n",
    "                <h4 style=\"margin: 0 0 10px 0;\">Road Segments</h4>\n",
    "            \"\"\"\n",
    "            \n",
    "            for rank, segment in enumerate(segments, 1):\n",
    "                # Round the value used for coloring\n",
    "                value = round(segment['time_per_100m'], 1) if 'average travel time' in metric_name.lower() else segment['count']\n",
    "                color = colormap(value)\n",
    "                \n",
    "                legend_html += f\"\"\"\n",
    "                <div style=\"margin-bottom: 8px;\">\n",
    "                    <span style=\"\n",
    "                        display: inline-block;\n",
    "                        width: 12px;\n",
    "                        height: 12px;\n",
    "                        background-color: {color};\n",
    "                        margin-right: 5px;\n",
    "                        border: 1px solid #666;\n",
    "                    \"></span>\n",
    "                    <strong>#{rank}</strong> OSMID: {segment['OSMID']}\n",
    "                    <br>\n",
    "                    <span style=\"margin-left: 17px; white-space: pre-line;\">\n",
    "                        {self._get_metric_display(segment, metric_name)}\n",
    "                    </span>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "                \n",
    "                # Add segment to map\n",
    "                coords = [(y, x) for x, y in segment['geometry'].coords]\n",
    "                folium.PolyLine(\n",
    "                    coords,\n",
    "                    weight=6,\n",
    "                    color=colormap(value),\n",
    "                    opacity=0.9,\n",
    "                    popup=self._create_popup_text(segment, rank)\n",
    "                ).add_to(m)\n",
    "                \n",
    "                # Add glowing effect\n",
    "                folium.PolyLine(\n",
    "                    coords,\n",
    "                    weight=10,\n",
    "                    color=colormap(value),\n",
    "                    opacity=0.3\n",
    "                ).add_to(m)\n",
    "                \n",
    "                # Add label\n",
    "                if len(coords) > 1:\n",
    "                    mid_point = coords[len(coords)//2]\n",
    "                    folium.DivIcon(\n",
    "                        html=f\"\"\"\n",
    "                        <div style=\"\n",
    "                            background-color: rgba(255, 255, 255, 0);\n",
    "                            border: 2px solid {color};\n",
    "                            border-radius: 4px;\n",
    "                            padding: 3px 6px;\n",
    "                            font-size: 8px;\n",
    "                            font-weight: bold;\n",
    "                            white-space: nowrap;\n",
    "                            box-shadow: 0 0 4px rgba(0,0,0,0.2);\n",
    "                        \">\n",
    "                            #{rank} - {segment['length']:.0f}m\n",
    "                        </div>\n",
    "                        \"\"\"\n",
    "                     ).add_to(folium.Marker(\n",
    "                         [segment['geometry'].coords[-1][1], segment['geometry'].coords[-1][0]],  # Use last coordinate for bottom placement\n",
    "                         icon=DivIcon(\n",
    "                             icon_size=(60, 36),\n",
    "                             icon_anchor=(30, 0)  # Anchor the icon at the bottom center\n",
    "                             )\n",
    "                         ).add_to(m)) #.add_to(folium.Marker(\n",
    "                    #     mid_point,\n",
    "                    #     icon=DivIcon(\n",
    "                    #         icon_size=(60, 36),\n",
    "                    #         icon_anchor=(30, 18)\n",
    "                    #     )\n",
    "                    # ).add_to(m))\n",
    "            \n",
    "            legend_html += \"</div>\"\n",
    "            m.get_root().html.add_child(folium.Element(legend_html))\n",
    "            \n",
    "            # Add colormap with proper caption\n",
    "            colormap.add_to(m)\n",
    "        \n",
    "        # Add title\n",
    "        title_html = self._create_title_html(title, len(segments), metric_name)\n",
    "        m.get_root().html.add_child(folium.Element(title_html))\n",
    "        \n",
    "        # Save map\n",
    "        output_path = os.path.join(self.analysis_dir, filename)\n",
    "        m.save(output_path)\n",
    "        return output_path\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def _create_popup_text(self, segment: Dict, rank: int) -> str:\n",
    "        \"\"\"Create enhanced popup text for segment\"\"\"\n",
    "        # Calculate actual speed\n",
    "        speed = segment['length'] / segment['avg_time'] if segment['avg_time'] > 0 else 0\n",
    "        speed_kmh = speed * 3.6\n",
    "        \n",
    "        return f\"\"\"\n",
    "        <div style='font-family: Arial; font-size: 12px; min-width: 200px;'>\n",
    "            <div style='background-color: #f8f9fa; padding: 8px; border-radius: 4px; margin-bottom: 8px;'>\n",
    "                <strong style='font-size: 14px;'>Rank #{rank}</strong><br>\n",
    "                <strong>OSMID:</strong> {segment['OSMID']}\n",
    "            </div>\n",
    "            <strong>Statistics:</strong><br>\n",
    "            • Traverse count: {segment.get('count', 'N/A')}<br>\n",
    "            • Average Speed: {speed_kmh:.1f} km/h<br>\n",
    "            • Length: {segment['length']:.0f} m<br>\n",
    "            • Time: {segment['avg_time']:.1f} s<br>\n",
    "            • Time per 100m: {(segment['avg_time'] / segment['length'] * 100):.1f} s\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "   \n",
    "\n",
    "    def _create_title_html(self, title: str, num_segments: int, metric_name: str) -> str:\n",
    "        \"\"\"Create HTML for map title\"\"\"\n",
    "        return f\"\"\"\n",
    "        <div style=\"\n",
    "            position: fixed;\n",
    "            top: 10px;\n",
    "            left: 50px;\n",
    "            width: 300px;\n",
    "            z-index: 1000;\n",
    "            padding: 10px;\n",
    "            background-color: white;\n",
    "            border-radius: 5px;\n",
    "            box-shadow: 0 0 5px rgba(0,0,0,0.2);\n",
    "        \">\n",
    "            <h4 style=\"margin: 0;\">{title}</h4>\n",
    "            <p style=\"margin: 5px 0 0 0; font-size: 12px;\">\n",
    "                Top {num_segments} segments ranked by {metric_name}\n",
    "            </p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "    def analyze_and_visualize(self):\n",
    "        \"\"\"Perform complete route analysis\"\"\"\n",
    "        try:\n",
    "            most_traversed = self.get_most_traversed_segments()\n",
    "            slowest_segments = self.get_slowest_segments()\n",
    "            \n",
    "            if not most_traversed and not slowest_segments:\n",
    "                logging.warning(\"No valid segments found for analysis\")\n",
    "                return None\n",
    "            \n",
    "            # Generate visualizations\n",
    "            results = {\n",
    "                'most_traversed': {\n",
    "                    'segments': most_traversed,\n",
    "                    'map_path': self.visualize_segments_enhanced(\n",
    "                        most_traversed,\n",
    "                        \"Most Frequently Traversed Road Segments\",\n",
    "                        \"most_traversed_segments.html\",\n",
    "                        \"traverse frequency\",\n",
    "                        ['#fff7ec', '#fee8c8', '#fdd49e', '#fdbb84', '#fc8d59', '#ef6548', '#d7301f', '#990000']\n",
    "                    )\n",
    "                },\n",
    "                'slowest_segments': {\n",
    "                    'segments': slowest_segments,\n",
    "                    'map_path': self.visualize_segments_enhanced(\n",
    "                        slowest_segments,\n",
    "                        \"Slowest Road Segments\",\n",
    "                        \"slowest_segments.html\",\n",
    "                        \"average travel time\",\n",
    "                        ['#f7fcfd', '#e0ecf4', '#bfd3e6', '#9ebcda', '#8c96c6', '#8c6bb1', '#88419d', '#6e016b']\n",
    "                    )\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in analyze_and_visualize: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "def process_trajectory_with_time(row):\n",
    "    \"\"\"Process trajectory with timestamps from the data\"\"\"\n",
    "    try:\n",
    "        coords = ast.literal_eval(row['POLYLINE'])\n",
    "        if not coords or len(coords) < 2:\n",
    "            return None\n",
    "            \n",
    "        start_timestamp = int(row['TIMESTAMP'])\n",
    "        timestamps = [start_timestamp + i * 15 for i in range(len(coords))]\n",
    "        \n",
    "        return {\n",
    "            'coords': coords,\n",
    "            'timestamps': timestamps,\n",
    "            'start_timestamp': start_timestamp\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Error processing trajectory: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading road network for Porto, Portugal...\n",
      "INFO:__main__:Loading trajectory data from kraggle_data/train/train.csv...\n",
      "100%|██████████| 1500/1500 [00:37<00:00, 39.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed trajectories and generated analysis in: map_matching_results\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def run_map_matching_pipeline(input_file: str, place: str, nrows: int = None) -> Dict:\n",
    "    \"\"\"\n",
    "    Run the complete map matching pipeline with the given parameters\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Set up logging\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Load road network\n",
    "        logger.info(f\"Loading road network for {place}...\")\n",
    "        G = ox.graph_from_place(place, network_type='drive')\n",
    "        nodes, edges = ox.graph_to_gdfs(G)\n",
    "        \n",
    "        # Add edge IDs if they don't exist\n",
    "        if 'OSMID' not in edges.columns and 'osmid' not in edges.columns:\n",
    "            logger.info(\"Creating unique identifiers for edges...\")\n",
    "            edges['OSMID'] = edges.apply(get_edge_identifier, axis=1)\n",
    "        \n",
    "        # Convert to UTM coordinates\n",
    "        utm_crs = 'EPSG:32629'  # UTM zone 29N for Porto\n",
    "        edges = edges.to_crs(utm_crs)\n",
    "        \n",
    "        # Load trajectory data\n",
    "        logger.info(f\"Loading trajectory data from {input_file}...\")\n",
    "        df = pd.read_csv(input_file, nrows=nrows)\n",
    "        \n",
    "        # Initialize matcher with default configuration\n",
    "        matcher = EnhancedViterbiMatcher(G, edges)\n",
    "        \n",
    "        # Process trajectories\n",
    "        matched_results = []\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            trajectory_data = process_trajectory_with_time(row)\n",
    "            if trajectory_data:\n",
    "                point_gdf = gpd.GeoDataFrame(\n",
    "                    geometry=[Point(x, y) for x, y in trajectory_data['coords']],\n",
    "                    crs='EPSG:4326'\n",
    "                ).to_crs(utm_crs)\n",
    "                \n",
    "                utm_coords = [(p.x, p.y) for p in point_gdf.geometry]\n",
    "                result = matcher.match_trajectory(utm_coords)\n",
    "                \n",
    "                if result['success']:\n",
    "                    matched_results.append({\n",
    "                        'match_result': result,\n",
    "                        'original_coords': trajectory_data['coords'],\n",
    "                        'timestamps': trajectory_data['timestamps'],\n",
    "                        'start_timestamp': trajectory_data['start_timestamp']\n",
    "                    })\n",
    "        \n",
    "        if not matched_results:\n",
    "            logger.warning(\"No trajectories were successfully matched\")\n",
    "            return None\n",
    "        \n",
    "        # Perform analysis\n",
    "        output_dir = 'map_matching_results'\n",
    "        route_analyzer = RouteAnalyzer(matcher, matched_results, output_dir)\n",
    "        analysis_results = route_analyzer.analyze_and_visualize()\n",
    "        \n",
    "        return {\n",
    "            'matched_results': matched_results,\n",
    "            'analysis_results': analysis_results,\n",
    "            'output_dir': output_dir\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in map matching pipeline: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    try:\n",
    "        results = run_map_matching_pipeline(\n",
    "            input_file='kraggle_data/train/train.csv',\n",
    "            place='Porto, Portugal',\n",
    "            nrows=1500\n",
    "        )\n",
    "        \n",
    "        if results:\n",
    "            print(f\"Successfully processed trajectories and generated analysis in: {results['output_dir']}\")\n",
    "        else:\n",
    "            print(\"Pipeline execution failed\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error running pipeline: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urbancom2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
